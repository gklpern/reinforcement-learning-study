![alt text](image.png)

Planning (Planlama):

Bir kararÄ±n sadece anlÄ±k getirisi deÄŸil, uzun vadeli etkileri de var.

Ã–rneÄŸin: â€œÅimdi tatlÄ± yemek mi, yoksa diyet mi yapmak?â€ â†’ kÄ±sa vadede tatlÄ± iyi hissettirir ama uzun vadede saÄŸlÄ±ÄŸa zararlÄ±.

Learning (Ã–ÄŸrenme):

Temporal Credit Assignment Problem: Hangi geÃ§miÅŸ kararÄ±m bugÃ¼nkÃ¼ Ã¶dÃ¼lÃ¼ getirdi?

Ã–rneÄŸin: 100 adÄ±m Ã¶nce aldÄ±ÄŸÄ±n anahtar yÃ¼zÃ¼nden bugÃ¼n kazandÄ±n. Ama algoritma nasÄ±l bilecek ki bu kadar eski bir aksiyonun bu sonucu doÄŸurduÄŸunu?

Bu RLâ€™in en temel teknik zorluklarÄ±ndan biridir.


# Markov Assumption

![alt text](image-1.png)

BazÄ± durumlarda Markov varsayÄ±mÄ± doÄŸru deÄŸildir.

Ã–rn: Bir Ã¶ÄŸrencinin performansÄ± â†’ sadece bugÃ¼nkÃ¼ bilgi deÄŸil, Ã¶nceki deneyimlere de baÄŸlÄ± olabilir.

BÃ¶yle durumlarda POMDP (Partially Observable Markov Decision Process) kullanÄ±lÄ±r.

ğŸ¯ Ã–zet

Markov varsayÄ±mÄ± RLâ€™in temel taÅŸÄ±.

Ã‡Ã¼nkÃ¼ bu sayede matematiksel olarak MDP (Markov Decision Process) tanÄ±mÄ± yapÄ±labiliyor.

Ajan: â€œSadece bugÃ¼nkÃ¼ stateâ€™i bilsem yeterâ€ diye dÃ¼ÅŸÃ¼nÃ¼r.

![alt text](image-2.png)


![alt text](image-3.png)